% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/cr_ft_text.R
\name{cr_ft_text}
\alias{cr_ft_pdf}
\alias{cr_ft_plain}
\alias{cr_ft_text}
\alias{cr_ft_xml}
\title{Get full text from a DOI}
\usage{
cr_ft_text(url, type = "xml", path = "~/.crossref", overwrite = TRUE,
  read = TRUE, verbose = TRUE, ...)

cr_ft_plain(url, path = "~/.crossref", overwrite = TRUE, read = TRUE,
  verbose = TRUE, ...)

cr_ft_xml(url, path = "~/.crossref", overwrite = TRUE, read = TRUE,
  verbose = TRUE, ...)

cr_ft_pdf(url, path = "~/.crossref", overwrite = TRUE, read = TRUE,
  verbose = TRUE, ...)
}
\arguments{
\item{url}{(character) A URL.}

\item{type}{(character) One of xml, plain, pdf, or all}

\item{path}{(character) Path to store pdfs in. Default: \code{~/.crossref/}}

\item{overwrite}{(logical) Overwrite file if it exists already? Default: TRUE}

\item{read}{(logical) If reading a pdf, this toggles whether we extract text from
the pdf or simply download. If TRUE, you get the text from the pdf back. If FALSE,
you only get back the metadata. Default: TRUE}

\item{verbose}{(logical) Print progress messages. Default: TRUE}

\item{...}{Named parameters passed on to \code{\link[httr]{GET}}}
}
\description{
Get full text from a DOI
}
\details{
Note that \code{\link{cr_ft_text}},
\code{\link{cr_ft_pdf}}, \code{\link{cr_ft_xml}}, \code{\link{cr_ft_plain}}
are not vectorized.

Note that some links returned will not in fact lead you to full text
content as you would understandbly think and expect. That is, if you
use the \code{filter} parameter with e.g., \code{\link{cr_works}} and
filter to only full text content, some links may actually give back
only metadata for an article. Elsevier is perhaps the worst offender,
for one because they have a lot of entries in Crossref TDM, but most
of the links that are apparently full text are not in facct full text,
but only metadata.
}
\examples{
\dontrun{
# pdf link
cr_ft_links(doi = "10.5555/515151", "pdf")

# xml and plain text links
out <- cr_works(filter=c(has_full_text = TRUE))
dois <- out$data$DOI
cr_ft_links(dois[2], "xml")
cr_ft_links(dois[1], "plain")
cr_ft_links(dois[1], "all")

# No links
cr_ft_links(cr_r(1), "xml")

# get full text
## elife
out <- cr_members(4374, filter=c(has_full_text = TRUE), works = TRUE)
(links <- cr_ft_links(out$data$DOI[10], "all"))
### xml
cr_ft_text(links, 'xml')
### pdf
cr_ft_text(links, "pdf", read=FALSE)
cr_ft_text(links, "pdf")

## pensoft
out <- cr_members(2258, filter=c(has_full_text = TRUE), works = TRUE)
(links <- cr_ft_links(out$data$DOI[1], "all"))
### xml
cr_ft_text(links, 'xml')
### pdf
cr_ft_text(links, "pdf", read=FALSE)
cr_ft_text(links, "pdf")

## hindawi
out <- cr_members(98, filter=c(has_full_text = TRUE), works = TRUE)
(links <- cr_ft_links(out$data$DOI[1], "all"))
### xml
cr_ft_text(links, 'xml')
### pdf
cr_ft_text(links, "pdf", read=FALSE)
cr_ft_text(links, "pdf")

## search for works with full text, and with CC-BY 3.0 license
### you can see available licenses with cr_licenses() function
out <-
 cr_works(filter = list(has_full_text = TRUE,
   license_url="http://creativecommons.org/licenses/by/3.0/"))
(links <- cr_ft_links(out$data$DOI[10], "all"))
cr_ft_text(links, 'xml')

## elsevier - they don't actually give full text, ha ha, jokes on us!
out <- cr_members(78, filter=c(has_full_text = TRUE), works = TRUE)
links <- cr_ft_links(out$data$DOI[1], "all")
cr_ft_text(links, 'xml') # notice how this is just metadata
### elsevier articles that are open access
#### one license is for open access articles, but none with full text available
cr_licenses(filter=list(member=78))
cr_works(filter=list(license_url="http://www.elsevier.com/open-access/userlicense/1.0/",
                     has_full_text=TRUE))

## You can use cr_ft_xml, cr_ft_plain, and cr_ft_pdf to go directly to that format
out <-
 cr_works(filter = list(has_full_text = TRUE,
   license_url="http://creativecommons.org/licenses/by/3.0/"))
(links <- cr_ft_links(out$data$DOI[10], "all"))
cr_ft_xml(links)
cr_ft_pdf(links)
}
}

